{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Preprocess Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jQ1BwuRPrI"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmfYpbWkKGmn",
        "outputId": "9ca65893-61a4-4c86-efe8-47413931fba9"
      },
      "source": [
        "!pip install PySastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PySastrawi in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3boNYSgSuGt"
      },
      "source": [
        "# Function to stem and stopword removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFclvjSFQ9Pw"
      },
      "source": [
        "stop = []\n",
        "with  open('/content/drive/MyDrive/Bangkit/stopword.txt') as f:\n",
        "    csv_file = csv.reader(f)\n",
        "    for word in csv_file:\n",
        "        stop.append(word[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdTFFxrCS4zY"
      },
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqoTSav1Q4af",
        "outputId": "90c41e82-8b1b-474f-8f07-1475abd208f9"
      },
      "source": [
        "print(stop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara', 'antaranya', 'apa', 'apaan', 'apabila', 'apakah', 'apalagi', 'apatah', 'artinya', 'asal', 'asalkan', 'atas', 'atau', 'ataukah', 'ataupun', 'awal', 'awalnya', 'bagai', 'bagaikan', 'bagaimana', 'bagaimanakah', 'bagaimanapun', 'bagi', 'bagian', 'bahkan', 'bahwa', 'bahwasanya', 'baik', 'bakal', 'bakalan', 'balik', 'banyak', 'bapak', 'baru', 'bawah', 'beberapa', 'begini', 'beginian', 'beginikah', 'beginilah', 'begitu', 'begitukah', 'begitulah', 'begitupun', 'bekerja', 'belakang', 'belakangan', 'belum', 'belumlah', 'benar', 'benarkah', 'benarlah', 'berada', 'berakhir', 'berakhirlah', 'berakhirnya', 'berapa', 'berapakah', 'berapalah', 'berapapun', 'berarti', 'berawal', 'berbagai', 'berdatangan', 'beri', 'berikan', 'berikut', 'berikutnya', 'berjumlah', 'berkali-kali', 'berkata', 'berkehendak', 'berkeinginan', 'berkenaan', 'berlainan', 'berlalu', 'berlangsung', 'berlebihan', 'bermacam', 'bermacam-macam', 'bermaksud', 'bermula', 'bersama', 'bersama-sama', 'bersiap', 'bersiap-siap', 'bertanya', 'bertanya-tanya', 'berturut', 'berturut-turut', 'bertutur', 'berujar', 'berupa', 'besar', 'betul', 'betulkah', 'biasa', 'biasanya', 'bila', 'bilakah', 'bisa', 'bisakah', 'boleh', 'bolehkah', 'bolehlah', 'buat', 'bukan', 'bukankah', 'bukanlah', 'bukannya', 'bulan', 'bung', 'cara', 'caranya', 'cukup', 'cukupkah', 'cukuplah', 'cuma', 'dahulu', 'dalam', 'dan', 'dapat', 'dari', 'daripada', 'datang', 'dekat', 'demi', 'demikian', 'demikianlah', 'dengan', 'depan', 'di', 'dia', 'diakhiri', 'diakhirinya', 'dialah', 'diantara', 'diantaranya', 'diberi', 'diberikan', 'diberikannya', 'dibuat', 'dibuatnya', 'didapat', 'didatangkan', 'digunakan', 'diibaratkan', 'diibaratkannya', 'diingat', 'diingatkan', 'diinginkan', 'dijawab', 'dijelaskan', 'dijelaskannya', 'dikarenakan', 'dikatakan', 'dikatakannya', 'dikerjakan', 'diketahui', 'diketahuinya', 'dikira', 'dilakukan', 'dilalui', 'dilihat', 'dimaksud', 'dimaksudkan', 'dimaksudkannya', 'dimaksudnya', 'diminta', 'dimintai', 'dimisalkan', 'dimulai', 'dimulailah', 'dimulainya', 'dimungkinkan', 'dini', 'dipastikan', 'diperbuat', 'diperbuatnya', 'dipergunakan', 'diperkirakan', 'diperlihatkan', 'diperlukan', 'diperlukannya', 'dipersoalkan', 'dipertanyakan', 'dipunyai', 'diri', 'dirinya', 'disampaikan', 'disebut', 'disebutkan', 'disebutkannya', 'disini', 'disinilah', 'ditambahkan', 'ditandaskan', 'ditanya', 'ditanyai', 'ditanyakan', 'ditegaskan', 'ditujukan', 'ditunjuk', 'ditunjuki', 'ditunjukkan', 'ditunjukkannya', 'ditunjuknya', 'dituturkan', 'dituturkannya', 'diucapkan', 'diucapkannya', 'diungkapkan', 'dong', 'dua', 'dulu', 'empat', 'enggak', 'enggaknya', 'entah', 'entahlah', 'guna', 'gunakan', 'hal', 'hampir', 'hanya', 'hanyalah', 'hari', 'harus', 'haruslah', 'harusnya', 'hendak', 'hendaklah', 'hendaknya', 'hingga', 'ia', 'ialah', 'ibarat', 'ibaratkan', 'ibaratnya', 'ibu', 'ikut', 'ingat', 'ingat-ingat', 'ingin', 'inginkah', 'inginkan', 'ini', 'inikah', 'inilah', 'itu', 'itukah', 'itulah', 'jadi', 'jadilah', 'jadinya', 'jangan', 'jangankan', 'janganlah', 'jauh', 'jawab', 'jawaban', 'jawabnya', 'jelas', 'jelaskan', 'jelaslah', 'jelasnya', 'jika', 'jikalau', 'juga', 'jumlah', 'jumlahnya', 'justru', 'kala', 'kalau', 'kalaulah', 'kalaupun', 'kalian', 'kami', 'kamilah', 'kamu', 'kamulah', 'kan', 'kapan', 'kapankah', 'kapanpun', 'karena', 'karenanya', 'kasus', 'kata', 'katakan', 'katakanlah', 'katanya', 'ke', 'keadaan', 'kebetulan', 'kecil', 'kedua', 'keduanya', 'keinginan', 'kelamaan', 'kelihatan', 'kelihatannya', 'kelima', 'keluar', 'kembali', 'kemudian', 'kemungkinan', 'kemungkinannya', 'kenapa', 'kepada', 'kepadanya', 'kesampaian', 'keseluruhan', 'keseluruhannya', 'keterlaluan', 'ketika', 'khususnya', 'kini', 'kinilah', 'kira', 'kira-kira', 'kiranya', 'kita', 'kitalah', 'kok', 'kurang', 'lagi', 'lagian', 'lah', 'lain', 'lainnya', 'lalu', 'lama', 'lamanya', 'lanjut', 'lanjutnya', 'lebih', 'lewat', 'lima', 'luar', 'macam', 'maka', 'makanya', 'makin', 'malah', 'malahan', 'mampu', 'mampukah', 'mana', 'manakala', 'manalagi', 'masa', 'masalah', 'masalahnya', 'masih', 'masihkah', 'masing', 'masing-masing', 'mau', 'maupun', 'melainkan', 'melakukan', 'melalui', 'melihat', 'melihatnya', 'memang', 'memastikan', 'memberi', 'memberikan', 'membuat', 'memerlukan', 'memihak', 'meminta', 'memintakan', 'memisalkan', 'memperbuat', 'mempergunakan', 'memperkirakan', 'memperlihatkan', 'mempersiapkan', 'mempersoalkan', 'mempertanyakan', 'mempunyai', 'memulai', 'memungkinkan', 'menaiki', 'menambahkan', 'menandaskan', 'menanti', 'menanti-nanti', 'menantikan', 'menanya', 'menanyai', 'menanyakan', 'mendapat', 'mendapatkan', 'mendatang', 'mendatangi', 'mendatangkan', 'menegaskan', 'mengakhiri', 'mengapa', 'mengatakan', 'mengatakannya', 'mengenai', 'mengerjakan', 'mengetahui', 'menggunakan', 'menghendaki', 'mengibaratkan', 'mengibaratkannya', 'mengingat', 'mengingatkan', 'menginginkan', 'mengira', 'mengucapkan', 'mengucapkannya', 'mengungkapkan', 'menjadi', 'menjawab', 'menjelaskan', 'menuju', 'menunjuk', 'menunjuki', 'menunjukkan', 'menunjuknya', 'menurut', 'menuturkan', 'menyampaikan', 'menyangkut', 'menyatakan', 'menyebutkan', 'menyeluruh', 'menyiapkan', 'merasa', 'mereka', 'merekalah', 'merupakan', 'meski', 'meskipun', 'meyakini', 'meyakinkan', 'minta', 'mirip', 'misal', 'misalkan', 'misalnya', 'mula', 'mulai', 'mulailah', 'mulanya', 'mungkin', 'mungkinkah', 'nah', 'naik', 'namun', 'nanti', 'nantinya', 'nyaris', 'nyatanya', 'oleh', 'olehnya', 'pada', 'padahal', 'padanya', 'pak', 'paling', 'panjang', 'pantas', 'para', 'pasti', 'pastilah', 'penting', 'pentingnya', 'per', 'percuma', 'perlu', 'perlukah', 'perlunya', 'pernah', 'persoalan', 'pertama', 'pertama-tama', 'pertanyaan', 'pertanyakan', 'pihak', 'pihaknya', 'pukul', 'pula', 'pun', 'punya', 'rasa', 'rasanya', 'rata', 'rupanya', 'saat', 'saatnya', 'saja', 'sajalah', 'saling', 'sama', 'sama-sama', 'sambil', 'sampai', 'sampai-sampai', 'sampaikan', 'sana', 'sangat', 'sangatlah', 'satu', 'saya', 'sayalah', 'se', 'sebab', 'sebabnya', 'sebagai', 'sebagaimana', 'sebagainya', 'sebagian', 'sebaik', 'sebaik-baiknya', 'sebaiknya', 'sebaliknya', 'sebanyak', 'sebegini', 'sebegitu', 'sebelum', 'sebelumnya', 'sebenarnya', 'seberapa', 'sebesar', 'sebetulnya', 'sebisanya', 'sebuah', 'sebut', 'sebutlah', 'sebutnya', 'secara', 'secukupnya', 'sedang', 'sedangkan', 'sedemikian', 'sedikit', 'sedikitnya', 'seenaknya', 'segala', 'segalanya', 'segera', 'seharusnya', 'sehingga', 'seingat', 'sejak', 'sejauh', 'sejenak', 'sejumlah', 'sekadar', 'sekadarnya', 'sekali', 'sekali-kali', 'sekalian', 'sekaligus', 'sekalipun', 'sekarang', 'sekarang', 'sekecil', 'seketika', 'sekiranya', 'sekitar', 'sekitarnya', 'sekurang-kurangnya', 'sekurangnya', 'sela', 'selain', 'selaku', 'selalu', 'selama', 'selama-lamanya', 'selamanya', 'selanjutnya', 'seluruh', 'seluruhnya', 'semacam', 'semakin', 'semampu', 'semampunya', 'semasa', 'semasih', 'semata', 'semata-mata', 'semaunya', 'sementara', 'semisal', 'semisalnya', 'sempat', 'semua', 'semuanya', 'semula', 'sendiri', 'sendirian', 'sendirinya', 'seolah', 'seolah-olah', 'seorang', 'sepanjang', 'sepantasnya', 'sepantasnyalah', 'seperlunya', 'seperti', 'sepertinya', 'sepihak', 'sering', 'seringnya', 'serta', 'serupa', 'sesaat', 'sesama', 'sesampai', 'sesegera', 'sesekali', 'seseorang', 'sesuatu', 'sesuatunya', 'sesudah', 'sesudahnya', 'setelah', 'setempat', 'setengah', 'seterusnya', 'setiap', 'setiba', 'setibanya', 'setidak-tidaknya', 'setidaknya', 'setinggi', 'seusai', 'sewaktu', 'siap', 'siapa', 'siapakah', 'siapapun', 'sini', 'sinilah', 'soal', 'soalnya', 'suatu', 'sudah', 'sudahkah', 'sudahlah', 'supaya', 'tadi', 'tadinya', 'tahu', 'tahun', 'tak', 'tambah', 'tambahnya', 'tampak', 'tampaknya', 'tandas', 'tandasnya', 'tanpa', 'tanya', 'tanyakan', 'tanyanya', 'tapi', 'tegas', 'tegasnya', 'telah', 'tempat', 'tengah', 'tentang', 'tentu', 'tentulah', 'tentunya', 'tepat', 'terakhir', 'terasa', 'terbanyak', 'terdahulu', 'terdapat', 'terdiri', 'terhadap', 'terhadapnya', 'teringat', 'teringat-ingat', 'terjadi', 'terjadilah', 'terjadinya', 'terkira', 'terlalu', 'terlebih', 'terlihat', 'termasuk', 'ternyata', 'tersampaikan', 'tersebut', 'tersebutlah', 'tertentu', 'tertuju', 'terus', 'terutama', 'tetap', 'tetapi', 'tiap', 'tiba', 'tiba-tiba', 'tidak', 'tidakkah', 'tidaklah', 'tiga', 'tinggi', 'toh', 'tunjuk', 'turut', 'tutur', 'tuturnya', 'ucap', 'ucapnya', 'ujar', 'ujarnya', 'umum', 'umumnya', 'ungkap', 'ungkapnya', 'untuk', 'usah', 'usai', 'waduh', 'wah', 'wahai', 'waktu', 'waktunya', 'walau', 'walaupun', 'wong', 'yaitu', 'yakin', 'yakni', 'yang']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mhdd7-fS7aT"
      },
      "source": [
        "dictionary = ArrayDictionary(stop)\n",
        "stopword = StopWordRemover(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QjVRW5eS8-g"
      },
      "source": [
        "# Preprocess Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_bC20BLVCWS"
      },
      "source": [
        "## Stem and Stopword removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "BZMCLwj1RfZh",
        "outputId": "fdfda883-4b68-48ea-d7b3-38d4de9ab343"
      },
      "source": [
        "dataset = pd.read_csv(r'/content/drive/MyDrive/Bangkit/new_news.csv')\n",
        "dataset['berita_preprocessed'] = dataset.apply(lambda x:  stopword.remove(stemmer.stem(x['berita'])), axis=1)\n",
        "# dataset['class'] = dataset['tagging'].replace({'Valid':1, 'Hoax':0})\n",
        "dataset.drop_duplicates(subset='berita_preprocessed', inplace=True)\n",
        "dataset.drop(columns=['berita', 'tagging'], inplace=True)\n",
        "dataset\n",
        "# dataset.to_csv(path_or_buf='/content/preprocessed.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9b646308a3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/Bangkit/new_news.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'berita_preprocessed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mstopword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'berita'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tagging'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hoax'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'berita_preprocessed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'berita'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tagging'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             return self.replace(\n\u001b[0;32m-> 6507\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6508\u001b[0m             )\n\u001b[1;32m   6509\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6551\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m                     )\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, mask, regex)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Calculate the mask once, prior to the call of comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_numeric_v_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;31m# GH#29553 avoid deprecation warnings from numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m         \u001b[0m_check_comparison_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_check_comparison_types\u001b[0;34m(result, a, b)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m             )\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ttq6Zd7Vhm3"
      },
      "source": [
        "## Split dataset to train, val, and test set (80, 10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UlhH5BwTq5v",
        "outputId": "50afc215-3850-4c7e-fd10-d190e630322c"
      },
      "source": [
        "trainset = dataset.sample(frac=0.8).reset_index(drop=True)\n",
        "print(trainset.head(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 berita_preprocessed  class\n",
            "0  menteri komunikasi informatika rudiantara kont...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raMOAAzluREq"
      },
      "source": [
        "trainset.to_csv(path_or_buf='/content/trainset.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WovMPVHkVtNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8d499b-498a-4661-da13-f4916bef8dc2"
      },
      "source": [
        "dataset = dataset.merge(trainset, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'].drop(columns=['_merge'])\n",
        "valset = dataset.sample(frac=0.5).reset_index(drop=True)\n",
        "print(valset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  berita_preprocessed  class\n",
            "0   badan narkotika nasional bnn rampung proses pe...      1\n",
            "1   masyakarat surabaya jawa timur heboh cuat isu ...      1\n",
            "2   stroke ganggu buluh darah otak ganggu upa sumb...      1\n",
            "3   lele rupa ikan habitat air tawar ikan ternak l...      0\n",
            "4   masyarakat percaya tusuk jarum daun telinga to...      1\n",
            "5   hidup aneka kuas rias wajah luk bersih debu ca...      0\n",
            "6   sikat gigi rupa alat mandi hilang kotor gigi s...      0\n",
            "7   aparat polisi polda lampung laku lidi antisipa...      1\n",
            "8   gaji presiden ri drastis capai rp 500 juta rp ...      0\n",
            "9   facebook tutup 24 april 2018 kemkominfo netize...      1\n",
            "10  kabar permen dot indikasi kandung narkoba sura...      0\n",
            "11  foto aksi 212 jilid 2 masuk masjid istiqlal pa...      1\n",
            "12  tusuk jarum telinga pasien stroke cegah darah ...      1\n",
            "13  aple buka suara kena iphone 6 lengkung ramai b...      1\n",
            "14  sebar kabar media sosial tahan teroris rumah t...      0\n",
            "15  massa daerah kamis 1 12 2016 malam mendatangan...      0\n",
            "16  edar pesan media sosial pesan singkat putar ce...      1\n",
            "17  kabar konsumen tanah air niat beli iphone 6 pl...      0\n",
            "18  muncul main pokemon go - alih pandang orang or...      1\n",
            "19  urus masjid istiqlal jakarta pusat mengijinkan...      1\n",
            "20  jakarta - iphone 6 plus lapor gadget apple mud...      1\n",
            "21  badan awas obat makan bpom nyata permen merk p...      1\n",
            "22  jakarta pokemon go rilis sambut orang game mob...      0\n",
            "23  rusuh rumah tahan rutan mako brimob kelapa dep...      1\n",
            "24  hidup aneka kuas rias wajah luk bersih debu ca...      0\n",
            "25  orang aktivitas temu orang tolong derita strok...      0\n",
            "26  gaji presiden ri potensi alami signifikan capa...      0\n",
            "27  pokemon go wabah tarik animo masyarakat dunia ...      1\n",
            "28  rusuh mako brimob kelapa depok jumat 10 11 mal...      1\n",
            "29  genap pecan luncur smartphone canggi hasil bes...      0\n",
            "30  jakarta - keluh iphone 6 plus handset milik ga...      1\n",
            "31  edar informasi dunia media sosial sikat gigi b...      1\n",
            "32  marak edar permen dot duga kandung narkoba nya...      1\n",
            "33  aksi 212 jilid 2 kota masjid istiqlal masuk pi...      0\n",
            "34  media sosial twitter ramai bahas aja cabut apl...      1\n",
            "35  jurnalmuslim com - film kartun pokemon larang ...      0\n",
            "36  menteri uang menkeu sri mulyani perintah bahas...      1\n",
            "37  isu bulu babi bahan sikat gigi tulis papar mar...      0\n",
            "38  makobrimob sore cekam akibat ampas lempar al-q...      0\n",
            "39  gaji presiden rp 62 juta anggap perintah renca...      0\n",
            "40  gubernur dki jakarta anies baswedan ananda suk...      0\n",
            "41  wacana menteri komunikasi informatika rudianta...      0\n",
            "42  menteri uang sri mulyani bahas kena gaji presi...      1\n",
            "43  masyarakat depok nasional kejut status media s...      1\n",
            "44  jejaring sosial edar informasi lele ikan jorok...      1\n",
            "45  minggu pasar benda cari cinta gadget kelas pre...      0\n",
            "46  game niantic inc rilis timbul polemik polemik ...      1\n",
            "47  kabar edar putar rencana gaji presiden wakil p...      1\n",
            "48  artikel tebar enak terjemah arti pokemon yahud...      1\n",
            "49  jakarta komunitas reyog ponorogo krp temu ment...      1\n",
            "50  edar foto aksi 212 jilid media sosial masuk ma...      1\n",
            "51  stroke rupa kondisi pasok darah tuju otak putu...      0\n",
            "52  menteri komunikasi informatika rudiantara kont...      0\n",
            "53  edar kabar rusuh rumah tahan rutan mako brimob...      0\n",
            "54  ramai bicara warga net media sosial facebook i...      1\n",
            "55  facebook cari teman amerika indonesia cari tem...      1\n",
            "56  komunitas reog ponorogo krp rencana gelar demo...      1\n",
            "57  jakarta-warganet bingung ketidakjelasan inform...      1\n",
            "58  2012 heboh muncul kuas sikat bebahan bulu babi...      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTMmlX9UyL63"
      },
      "source": [
        "valset.to_csv(path_or_buf='/content/valset.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TelUvNgaYG9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e2b6bd-5569-4aa9-ad26-b7fbc47d948c"
      },
      "source": [
        "testset = dataset.merge(valset, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only'].drop(columns=['_merge']).reset_index(drop=True)\n",
        "print(testset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  berita_preprocessed  class\n",
            "0   isu ikan lele kandung sel kanker jejaring soci...      1\n",
            "1   clarias ikan lele topik bincang hangat putar d...      1\n",
            "2   lele rupa salah jenis ikan favorit saji menu m...      1\n",
            "3   lele ikan rupa favorit orang milik enak milik ...      0\n",
            "4   lele rupa ikan habitat air tawar ikan ternak l...      0\n",
            "5   lele salah bahan makan suka masyarakat tanah a...      1\n",
            "6   isu ikan lele kandung sel kanker jejaring sosi...      0\n",
            "7   heboh berita hoax putar konspirasi kanker arti...      1\n",
            "8   jejaring sosial edar informasi ikan lele ikan ...      1\n",
            "9   jejaring sosial edar informasi lele ikan jorok...      0\n",
            "10  baca baca tulis edar media sosial kena tusuk j...      1\n",
            "11  metode spesialis jantung rumah sakit harap dr ...      1\n",
            "12  doktersehat com stroke rupa sakit saraf akibat...      0\n",
            "13  apple kabar kembang iphone usung ukur layar ka...      1\n",
            "14  minggu muncul lapor iphone 6 plus mudah lengku...      1\n",
            "15  apple nyata iphone 6 iphone 6 plus lengkung ja...      1\n",
            "16  california - keluh iphone 6 plus ramai dunia m...      1\n",
            "17  genap produk apple iphone 6 iphone 6 plus ragu...      0\n",
            "18  selesai iphone 5 lempar pasar apple ide genera...      0\n",
            "19  foto iphone 6 mudah lengkung edar internet kut...      0\n",
            "20  konsulat jenderal republik indonesia davao cit...      1\n",
            "21  ribu seniman reog ponorogo gelar demonstrasi s...      0\n",
            "22  jakarta komunitas reog ponorogo krp serah berk...      0\n",
            "23  metrotvnews com jakarta buah reog ponorogo kon...      1\n",
            "24  anggota komunitas reog ponorogo krp kantor men...      1\n",
            "25  jakarta aksi 212 selasa 21 2 2017 kemarin edar...      1\n",
            "26  laku aksi bela islam negara laku masyarakat mu...      0\n",
            "27  ribu massa aksi 212 daerah tahan latar mesjid ...      0\n",
            "28  badan kelola masjid istiqlal bppmi ban kabar e...      1\n",
            "29  dunia maya ribut kuas sikat sikat gigi bristle...      1\n",
            "30  sikat gigi rupa alat mandi hilang kotor gigi s...      0\n",
            "31  dream - masyarakat muslim heboh kabar sikat gi...      0\n",
            "32  dunia maya ribut sikat gigi bristle anggap bab...      0\n",
            "33  badan awas obat makan bpom laku uji sampel per...      1\n",
            "34  produk permen bentuk dot kantong izin produksi...      1\n",
            "35  kait temu jajan permen kandung narkoba kalang ...      0\n",
            "36  kota surabaya heboh temu permen dot kemas boto...      0\n",
            "37  surabaya si online -jajaran perintah kota sura...      0\n",
            "38  demam pokemon go masyarakat iring rumor senang...      1\n",
            "39  jurnaldigital com bupati cianjur irvan rivano ...      0\n",
            "40  game pokemon go wabah tarik animo masyarakat d...      1\n",
            "41  napi teroris rumah tahan kelapa depok jawa bar...      1\n",
            "42  narapidana napi teroris markas komando mako br...      1\n",
            "43  orang netizen berita rusuh rutan mako brimob d...      0\n",
            "44  aja meng-uninstall aplikasi traveloka seliwer ...      0\n",
            "45  himpun alumni kolese kanisius pakkj nyata resm...      0\n",
            "46  aja boikot traveloka meng-uninstall aplikasi t...      0\n",
            "47  aja meng-uninstall aplikasi traveloka seliwer ...      0\n",
            "48  viral wak gera aja netizen meng-uninstall apli...      1\n",
            "49  perintah ancam tutup media sosial situs facebo...      0\n",
            "50  buah kabar facebook blokir tanggal 24 april 20...      1\n",
            "51  pekan edar konten linimasa facebook nyata medi...      1\n",
            "52  gaji presiden ri drastis capai rp 500 juta rp ...      0\n",
            "53  kabar edar putar rencana gaji presiden wakil p...      1\n",
            "54  kabar edar putar rencana gaji presiden wakil p...      1\n",
            "55  menteri uang sri mulyani bahas gaji presiden b...      1\n",
            "56  menteri uang sri mulyani indrawati lihat kesal...      1\n",
            "57  kepala biro pers media informasi sekretariat p...      1\n",
            "58  kabar edar putar rencana gaji presiden wakil p...      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivq1Xa_xyT9F"
      },
      "source": [
        "testset.to_csv(path_or_buf='/content/testset.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1wy67NvVb56"
      },
      "source": [
        "# Tokenizer the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QDJ0EyR5pqT"
      },
      "source": [
        "## Initialize variable for tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKAFRZzYOZM"
      },
      "source": [
        "vocab_size = 3000\n",
        "embedding_dim = 16\n",
        "max_length = 4610\n",
        "trunc_type='pre'\n",
        "oov_tok = \"<OOV>\"\n",
        "pad_type = 'post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKpo27QG5vm5"
      },
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8jvz00_52wy",
        "outputId": "0c81bdc4-b971-4f38-bfe9-e683f393550b"
      },
      "source": [
        "trainset_x = trainset['berita_preprocessed'].to_list()\n",
        "trainset_y = trainset['class'].to_numpy()\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(trainset_x)\n",
        "trainset_x_seq = tokenizer.texts_to_sequences(trainset_x)\n",
        "trainset_padded = pad_sequences(trainset_x_seq, maxlen=max_length, truncating=trunc_type, padding=pad_type)\n",
        "print(trainset_padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  62  200  431 ...    0    0    0]\n",
            " [ 928  234  113 ...    0    0    0]\n",
            " [1062  155   24 ...    0    0    0]\n",
            " ...\n",
            " [ 972   24   61 ...    0    0    0]\n",
            " [  15  102  101 ...    0    0    0]\n",
            " [ 351   24   61 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbHohmlUupgT",
        "outputId": "3c9f5200-cd9a-4ec7-8c9d-169554e077dd"
      },
      "source": [
        "print(trainset_x_seq[5])\n",
        "print(trainset_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 404, 50, 2159, 10, 25, 40, 107, 38, 9, 11, 38, 140, 1, 556, 1501, 284, 40, 1729, 9, 11, 106, 10, 38, 40, 9, 11, 204, 38, 1502, 432, 40, 266, 40, 29, 251, 447, 1, 1302, 251, 271, 447, 266, 40, 251, 1303, 447, 1117, 40, 557, 736, 601, 1304, 447, 40, 42, 40, 653, 899, 1071, 218, 48, 1022, 493, 5, 674, 173, 674, 173, 496, 497, 1, 1412, 826, 151, 737, 244, 50, 10, 10, 25, 40, 107, 11, 675, 325, 266, 40, 1729, 9, 11, 225, 40, 1413, 588, 1414, 1415, 558, 1302, 2160, 1305, 618, 1225, 251, 271, 447, 266, 40, 251, 1303, 447, 1117, 40, 557, 736, 601, 1304, 447, 40, 676, 138, 151, 571, 151, 571, 40, 38, 50, 10, 738, 39, 10, 25, 2161, 40, 525, 217, 9, 257, 271, 976, 271, 1226, 572, 1118, 9, 257, 217, 11, 739, 619, 827, 271, 976, 38, 50, 10, 736, 572, 271, 1226, 2162, 38, 50, 10, 10, 25, 1503, 206, 38, 50, 10, 39, 10, 25, 9, 257, 620, 1306, 38, 9, 11, 38, 11, 140, 556, 134, 1908, 1416, 140, 307, 173, 467, 11, 140, 191, 241, 1, 39, 9, 50, 10, 10, 25, 1027, 50, 50, 10, 9, 11, 16, 34, 68, 432, 10, 50, 9, 11, 59, 77, 106, 507, 40, 738, 507, 266, 41, 456, 11, 573, 1119, 29, 106, 28, 10, 9, 11, 573, 10, 25, 9, 1119, 1909, 235, 542, 422, 1072, 699, 10, 25, 11, 77, 1504, 1505, 701, 1608, 507, 40, 2163, 1910, 2164, 2165, 1911, 828, 147, 2166, 2167, 1307, 1504, 1505, 369, 68, 1173, 10, 9, 11, 201, 1, 1, 507, 558, 40, 1, 738, 1307, 1, 1, 1, 2529, 588, 1, 1, 1, 2529, 1912, 1913, 828, 1, 558, 370, 1308, 1, 1608, 1, 369, 677, 50, 10, 10, 25, 11, 59, 40, 371, 266, 40, 559, 448, 9, 739, 9, 827, 619, 38, 50, 38, 572, 543, 38, 34, 217, 38, 219, 1170, 38, 9, 257, 525, 12, 38, 378, 251, 1227, 12, 186, 38, 654, 1120, 308, 378, 869, 12]\n",
            "[0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1\n",
            " 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0\n",
            " 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0\n",
            " 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egEvoSLz6w52"
      },
      "source": [
        "## Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh91UxSm61Vn",
        "outputId": "14c3097a-1931-45f0-bacc-b298d7f712d0"
      },
      "source": [
        "valset_x = valset['berita_preprocessed'].to_list()\n",
        "valset_y = valset['class'].to_numpy()\n",
        "valset_x_seq = tokenizer.texts_to_sequences(valset_x)\n",
        "valset_padded = pad_sequences(valset_x_seq, maxlen=max_length, truncating=trunc_type, padding=pad_type)\n",
        "print(valset_padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 254  547  475 ...    0    0    0]\n",
            " [   1  165  146 ...    0    0    0]\n",
            " [  14  608  236 ...    0    0    0]\n",
            " ...\n",
            " [ 351   24   61 ...    0    0    0]\n",
            " [  47 1276 1566 ...    0    0    0]\n",
            " [1089  636  158 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnfuiN907Iwp"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZaqZJNI7M8Y",
        "outputId": "25ebe93c-1852-4e69-8837-37d63a44bc7c"
      },
      "source": [
        "testset_x = testset['berita_preprocessed'].to_list()\n",
        "testset_y = testset['class'].to_numpy()\n",
        "testset_x_seq = tokenizer.texts_to_sequences(testset_x)\n",
        "testset_padded = pad_sequences(testset_x_seq, maxlen=max_length, truncating=trunc_type, padding=pad_type)\n",
        "print(testset_padded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 78   3   2 ...   0   0   0]\n",
            " [  1   3   2 ...   0   0   0]\n",
            " [  2  28  16 ...   0   0   0]\n",
            " ...\n",
            " [ 62 434 363 ...   0   0   0]\n",
            " [ 92 820 650 ...   0   0   0]\n",
            " [ 31  18 718 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}